{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.49.0 to work with saurav_aml\n"
        }
      ],
      "execution_count": 178,
      "metadata": {
        "gather": {
          "logged": 1679568563363
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "if 'insurance dataset' not in ws.datasets:\r\n",
        "    Dataset.File.upload_directory(src_dir='data',\r\n",
        "                              target=DataPath(default_ds, 'insurance-data/')\r\n",
        "                              )\r\n",
        "\r\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\r\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'insurance-data/*.csv'))\r\n",
        "\r\n",
        "    # Register the tabular dataset\r\n",
        "    try:\r\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \r\n",
        "                                name='insurance dataset',\r\n",
        "                                description='insurance data',\r\n",
        "                                tags = {'format':'CSV'},\r\n",
        "                                create_new_version=True)\r\n",
        "        print('Dataset registered.')\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "else:\r\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset already registered.\n"
        }
      ],
      "execution_count": 179,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679568564760
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "# Create a folder for the pipeline step files\r\n",
        "experiment_folder = 'insurance_pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "insurance_pipeline\n"
        }
      ],
      "execution_count": 180,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679568565945
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_insurance.py\r\n",
        "# Import libraries\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "# import pandas as pd\r\n",
        "# import numpy as np\r\n",
        "from azureml.core import Run\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import scipy.stats as stats #It has all the probability distributions available along with many statistical functions.\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "# import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# import seaborn as sns\r\n",
        "# import warnings\r\n",
        "# warnings.filterwarnings('ignore') # To supress warnings\r\n",
        "# sns.set(style=\"darkgrid\") # set the background for the graphs\r\n",
        "from scipy.stats import skew\r\n",
        "from statsmodels.stats.proportion import proportions_ztest # For proportion Z-test\r\n",
        "from statsmodels.formula.api import ols      # For n-way ANOVA\r\n",
        "from statsmodels.stats.anova import anova_lm # For n-way ANOVA\r\n",
        "from scipy.stats import chi2_contingency   # For Chi-Sq \r\n",
        "\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\r\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\r\n",
        "args = parser.parse_args()\r\n",
        "prep_folder = args.prepped_data\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the data (passed as an input dataset)\r\n",
        "print(\"Loading Data...\")\r\n",
        "df = run.input_datasets['raw_data'].to_pandas_dataframe()\r\n",
        "# df = df.replace('?',np.NaN)\r\n",
        "# Log raw row count\r\n",
        "row_count = (len(df))\r\n",
        "run.log('raw_rows', row_count)\r\n",
        "\r\n",
        "# def iqr_outlier_cap(df,column):\r\n",
        "#     q1 = df[column].quantile(0.25)\r\n",
        "#     q2 = df[column].quantile(0.75)\r\n",
        "#     #finding out the value of Inter Quartile Range\r\n",
        "#     # IQR= np.subtract(q2,q1)\r\n",
        "#     IQR= (q2.astype(np.float32) - q1.astype(np.float32)).astype(np.bool)\r\n",
        "#     #defining max and min limits\r\n",
        "#     max_limit = q2 + (1.5 * IQR)\r\n",
        "#     # min_limit = np.subtract(q1, (1.5 * IQR)) \r\n",
        "#     min_limit=(q1.astype(np.float32) - (1.5 * IQR).astype(np.float32)).astype(np.bool)\r\n",
        "#     #capping\r\n",
        "#     df_new = pd.DataFrame(np.where(df[column] > max_limit, max_limit, \r\n",
        "#              (np.where(df[column] < min_limit, min_limit, df[column]))), columns=[column])\r\n",
        "#     return df_new\r\n",
        "\r\n",
        "def Preprocessing(df):\r\n",
        "    \"\"\"Data Pre-processing\"\"\"\r\n",
        "    # if '?' in the datset which we have to remove by NaN Values\r\n",
        "    df = df.replace('?',np.NaN)\r\n",
        "\r\n",
        "    df['collision_type'].fillna(df['collision_type'].mode()[0], inplace = True)\r\n",
        "    df['property_damage'].fillna('NO', inplace = True)\r\n",
        "    df['police_report_available'].fillna('NO', inplace = True)\r\n",
        "\r\n",
        "    # let's extrat days, month and year from policy bind date\r\n",
        "    # df['policy_bind_date'] = pd.to_datetime(df['policy_bind_date'], errors = 'coerce')\r\n",
        "\r\n",
        "    # dropping unimportant columns\r\n",
        "    # df = df.drop(columns = [\r\n",
        "    #     'umbrella_limit', \r\n",
        "    #     '_c39'])\r\n",
        "\r\n",
        "    df.drop(['_c39'], axis=1, inplace=True)    \r\n",
        "\r\n",
        "    numeric_data = df._get_numeric_data()\r\n",
        "    cat_data = df.select_dtypes(include=['object'])\r\n",
        "\r\n",
        "    # lst=[]\r\n",
        "    # for i in numeric_data.columns:\r\n",
        "    #     lst.append(iqr_outlier_cap(numeric_data,i))\r\n",
        "    # numeric_data_cap=pd.concat(lst,axis=1)\r\n",
        "\r\n",
        "    for c in cat_data:\r\n",
        "        lbl = LabelEncoder()\r\n",
        "        lbl.fit(cat_data[c].values)\r\n",
        "        cat_data[c] = lbl.transform(cat_data[c].values)\r\n",
        "\r\n",
        "\r\n",
        "    # Normalize the numeric columns\r\n",
        "    # scaler = MinMaxScaler()\r\n",
        "\r\n",
        "    # num_data_clean = scaler.fit_transform(numeric_data_cap)\r\n",
        "\r\n",
        "    clean_data = pd.concat([numeric_data,cat_data],axis=1)\r\n",
        "\r\n",
        "    # clean_data = scaler.fit_transform(clean_data)\r\n",
        "    \r\n",
        "    \r\n",
        "    return clean_data\r\n",
        "\r\n",
        "dataPrep = Preprocessing(df)\r\n",
        "\r\n",
        "# # Log processed rows\r\n",
        "row_count = (len(df))\r\n",
        "run.log('processed_rows', row_count)\r\n",
        "\r\n",
        "# Save the prepped data\r\n",
        "print(\"Saving Data...\")\r\n",
        "os.makedirs(prep_folder, exist_ok=True)\r\n",
        "save_path_1 = os.path.join(prep_folder,'prep_data.csv')\r\n",
        "dataPrep.to_csv(save_path_1, index=False, header=True)\r\n",
        "\r\n",
        "# End the run\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting insurance_pipeline/prep_insurance.py\n"
        }
      ],
      "execution_count": 181,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_insurance.py\r\n",
        "# Import libraries\r\n",
        "\r\n",
        "\r\n",
        "from azureml.core import Run, Model\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "# from azureml.core import Run\r\n",
        "import argparse, joblib, os\r\n",
        "import argparse\r\n",
        "from imblearn.over_sampling import SMOTE\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import accuracy_score, recall_score, classification_report, cohen_kappa_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "# from sklearn.tree import RandomForestClassifier\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\r\n",
        "args = parser.parse_args()\r\n",
        "training_data = args.training_data\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the prepared data file in the training folder\r\n",
        "print(\"Loading Data...\")\r\n",
        "file_path = os.path.join(training_data,'prep_data.csv')\r\n",
        "data_prep = pd.read_csv(file_path)\r\n",
        "\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "import argparse\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--n_estimators\", type=int)\r\n",
        "parser.add_argument(\"--min_samples_leaf\", type=int)\r\n",
        "parser.add_argument(\"--datafolder\", type=str)\r\n",
        "\r\n",
        "args, unknown = parser.parse_known_args()\r\n",
        "\r\n",
        "ne = args.n_estimators\r\n",
        "msl = args.min_samples_leaf\r\n",
        "\r\n",
        "print(ne, msl)\r\n",
        "\r\n",
        "# X = data_prep.iloc[:, 0:-1]\r\n",
        "\r\n",
        "# y = data_prep.iloc[:, -1]\r\n",
        "X = data_prep.drop(\"fraud_reported\",axis=1)\r\n",
        "y=data_prep[\"fraud_reported\"]\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1234)\r\n",
        "#smote\r\n",
        "\r\n",
        "sm = SMOTE(random_state = 2)\r\n",
        "X_train, y_train= sm.fit_resample(X_train, y_train.ravel())\r\n",
        "\r\n",
        "# Baseline Random forest based Model\r\n",
        "# rfc = RandomForestClassifier(n_estimators=ne, min_samples_leaf=msl)\r\n",
        "rfc = RandomForestClassifier()\r\n",
        "\r\n",
        "rfcg = rfc.fit(X_train, y_train) # fit on training data\r\n",
        "Y_predict = rfcg.predict(X_test)\r\n",
        "\r\n",
        "# Get the probability score - Scored Probabilities\r\n",
        "Y_prob = rfcg.predict_proba(X_test)[:, 1]\r\n",
        "\r\n",
        "# Get Confusion matrix and the accuracy/score - Evaluate\r\n",
        "\r\n",
        "cm    = confusion_matrix(y_test, Y_predict)\r\n",
        "accuracy = accuracy_score(y_test, Y_predict)\r\n",
        "\r\n",
        "# Create the confusion matrix dictionary\r\n",
        "cm_dict = {\"schema_type\": \"confusion_matrix\",\r\n",
        "           \"schema_version\": \"v1\",\r\n",
        "           \"data\": {\"class_labels\": [\"N\", \"Y\"],\r\n",
        "                    \"matrix\": cm.tolist()}\r\n",
        "           }\r\n",
        "\r\n",
        "run.log(\"TotalObservations\", len(data_prep))\r\n",
        "run.log_confusion_matrix(\"ConfusionMatrix\", cm_dict)\r\n",
        "run.log(\"Accuracy\", accuracy)\r\n",
        "\r\n",
        "\r\n",
        "# Save the trained model in the outputs folder\r\n",
        "print(\"Saving model...\")\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "model_file = os.path.join('outputs', 'insurance_model.pkl')\r\n",
        "joblib.dump(value=rfc, filename=model_file)\r\n",
        "\r\n",
        "# Register the model\r\n",
        "print('Registering model...')\r\n",
        "Model.register(workspace=run.experiment.workspace,\r\n",
        "               model_path = model_file,\r\n",
        "               model_name = 'insurance_model',\r\n",
        "               tags={'Training context':'Pipeline'},\r\n",
        "               properties={'Accuracy': np.float(accuracy)})\r\n",
        "\r\n",
        "\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting insurance_pipeline/train_insurance.py\n"
        }
      ],
      "execution_count": 182,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"saurav-compute-cluster\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 183,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679568375544
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\r\n",
        "name: experiment_env\r\n",
        "dependencies:\r\n",
        "- python=3.8\r\n",
        "- scikit-learn\r\n",
        "- ipykernel\r\n",
        "- matplotlib\r\n",
        "- pandas\r\n",
        "- numpy\r\n",
        "- statsmodels\r\n",
        "- scipy\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults\r\n",
        "  - pyarrow\r\n",
        "  - imblearn\r\n",
        "  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "\r\n",
        "# Create a Python environment for the experiment (from a .yml file)\r\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\r\n",
        "\r\n",
        "# Register the environment \r\n",
        "experiment_env.register(workspace=ws)\r\n",
        "registered_env = Environment.get(ws, 'experiment_env')\r\n",
        "\r\n",
        "# Create a new runconfig object for the pipeline\r\n",
        "pipeline_run_config = RunConfiguration()\r\n",
        "\r\n",
        "# Use the compute you created above. \r\n",
        "pipeline_run_config.target = pipeline_cluster\r\n",
        "\r\n",
        "# Assign the environment to the run configuration\r\n",
        "pipeline_run_config.environment = registered_env\r\n",
        "\r\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679568507345
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "insurance_ds = ws.datasets.get(\"insurance dataset\")\r\n",
        "\r\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\r\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\r\n",
        "\r\n",
        "# Step 1, Run the data prep script\r\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"prep_insurance.py\",\r\n",
        "                                arguments = ['--input-data', insurance_ds.as_named_input('raw_data'),\r\n",
        "                                             '--prepped-data', prepped_data],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "# Step 2, run the training script\r\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"train_insurance.py\",\r\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679568507532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Construct the pipeline\r\n",
        "pipeline_steps = [prep_step, train_step]\r\n",
        "pipeline_new = Pipeline(workspace=ws, steps=pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "# Create an experiment and run the pipeline\r\n",
        "experiment_new = Experiment(workspace=ws, name = 'saurav-insurance-pipeline')\r\n",
        "pipeline_run = experiment_new.submit(pipeline_new, regenerate_outputs=True)\r\n",
        "print(\"Pipeline submitted for execution.\")\r\n",
        "RunDetails(pipeline_run).show()\r\n",
        "pipeline_run.wait_for_completion(show_output=True)\r\n",
        "     "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679568507560
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for run in pipeline_run.get_children():\r\n",
        "    print(run.name, ':')\r\n",
        "    metrics = run.get_metrics()\r\n",
        "    for metric_name in metrics:\r\n",
        "        print('\\t',metric_name, \":\", metrics[metric_name])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679568507585
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "for model in Model.list(ws):\r\n",
        "    print(model.name, 'version:', model.version)\r\n",
        "    for tag_name in model.tags:\r\n",
        "        tag = model.tags[tag_name]\r\n",
        "        print ('\\t',tag_name, ':', tag)\r\n",
        "    for prop_name in model.properties:\r\n",
        "        prop = model.properties[prop_name]\r\n",
        "        print ('\\t',prop_name, ':', prop)\r\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679568507617
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}