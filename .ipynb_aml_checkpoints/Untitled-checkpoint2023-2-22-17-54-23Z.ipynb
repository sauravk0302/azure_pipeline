{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.49.0 to work with saurav_aml\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1679506339969
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "if 'insurance dataset' not in ws.datasets:\r\n",
        "    Dataset.File.upload_directory(src_dir='data',\r\n",
        "                              target=DataPath(default_ds, 'insurance-data/')\r\n",
        "                              )\r\n",
        "\r\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\r\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'insurance-data/*.csv'))\r\n",
        "\r\n",
        "    # Register the tabular dataset\r\n",
        "    try:\r\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \r\n",
        "                                name='insurance dataset',\r\n",
        "                                description='insurance data',\r\n",
        "                                tags = {'format':'CSV'},\r\n",
        "                                create_new_version=True)\r\n",
        "        print('Dataset registered.')\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "else:\r\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset already registered.\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679506342295
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "# Create a folder for the pipeline step files\r\n",
        "experiment_folder = 'insurance_pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "insurance_pipeline\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679506343935
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_insurance.py\r\n",
        "# Import libraries\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from azureml.core import Run\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\r\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\r\n",
        "args = parser.parse_args()\r\n",
        "prep_folder = args.prepped_data\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the data (passed as an input dataset)\r\n",
        "print(\"Loading Data...\")\r\n",
        "df = run.input_datasets['raw_data'].to_pandas_dataframe()\r\n",
        "\r\n",
        "# Log raw row count\r\n",
        "row_count = (len(df))\r\n",
        "run.log('raw_rows', row_count)\r\n",
        "\r\n",
        "\r\n",
        "def Preprocessing(df):\r\n",
        "    \"\"\"Data Pre-processing\"\"\"\r\n",
        "    # if '?' in the datset which we have to remove by NaN Values\r\n",
        "    df = df.replace('?',np.NaN)\r\n",
        "\r\n",
        "    # missing value treatment using fillna\r\n",
        "\r\n",
        "    # we will replace the '?' by the most common collision type as we are unaware of the type.\r\n",
        "    df['collision_type'].fillna(df['collision_type'].mode()[0], inplace = True)\r\n",
        "\r\n",
        "    # It may be the case that there are no responses for property damage then we might take it as No property damage.\r\n",
        "    df['property_damage'].fillna('NO', inplace = True)\r\n",
        "\r\n",
        "    # again, if there are no responses fpr police report available then we might take it as No report available\r\n",
        "    df['police_report_available'].fillna('NO', inplace = True)\r\n",
        "\r\n",
        "    # let's extrat days, month and year from policy bind date\r\n",
        "    df['policy_bind_date'] = pd.to_datetime(df['policy_bind_date'], errors = 'coerce')\r\n",
        "\r\n",
        "    # let's encode the fraud report to numerical values\r\n",
        "    df['fraud_reported'] = df['fraud_reported'].replace(('Y','N'),(0,1))\r\n",
        "\r\n",
        "    # dropping unimportant columns\r\n",
        "    df = df.drop(columns = [\r\n",
        "        'policy_number', \r\n",
        "        'insured_zip', \r\n",
        "        'policy_bind_date', \r\n",
        "        'incident_date', \r\n",
        "        'incident_location', \r\n",
        "        '_c39', \r\n",
        "        'auto_year', \r\n",
        "        'incident_hour_of_the_day'])\r\n",
        "\r\n",
        "    numeric_data = df._get_numeric_data()\r\n",
        "    cat_data = df.select_dtypes(include=['object'])\r\n",
        "\r\n",
        "    # Normalize the numeric columns\r\n",
        "    scaler = MinMaxScaler()\r\n",
        "\r\n",
        "    num_data_clean = scaler.fit_transform(numeric_data)\r\n",
        "\r\n",
        "    clean_data = pd.concat([pd.get_dummies(cat_data), numeric_data], axis=1)\r\n",
        "\r\n",
        "    return clean_data\r\n",
        "\r\n",
        "dataPrep = Preprocessing(df)\r\n",
        "\r\n",
        "# remove nulls\r\n",
        "# insurance = insurance.dropna()\r\n",
        "\r\n",
        "# # Normalize the numeric columns\r\n",
        "# scaler = MinMaxScaler()\r\n",
        "# num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\r\n",
        "# diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\r\n",
        "\r\n",
        "# # Log processed rows\r\n",
        "row_count = (len(df))\r\n",
        "run.log('processed_rows', row_count)\r\n",
        "\r\n",
        "# Save the prepped data\r\n",
        "print(\"Saving Data...\")\r\n",
        "os.makedirs(prep_folder, exist_ok=True)\r\n",
        "save_path_1 = os.path.join(prep_folder,'prep_data.csv')\r\n",
        "dataPrep.to_csv(save_path_1, index=False, header=True)\r\n",
        "\r\n",
        "# End the run\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting insurance_pipeline/prep_insurance.py\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_insurance.py\r\n",
        "# Import libraries\r\n",
        "from azureml.core import Run, Model\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "import os\r\n",
        "# from azureml.core import Run\r\n",
        "import argparse, joblib, os\r\n",
        "import argparse\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import accuracy_score, recall_score, classification_report, cohen_kappa_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "# from sklearn.tree import RandomForestClassifier\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\r\n",
        "args = parser.parse_args()\r\n",
        "training_data = args.training_data\r\n",
        "\r\n",
        "# Get the experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# load the prepared data file in the training folder\r\n",
        "print(\"Loading Data...\")\r\n",
        "file_path = os.path.join(training_data,'prep_data.csv')\r\n",
        "data_prep = pd.read_csv(file_path)\r\n",
        "\r\n",
        "\r\n",
        "# Get parameters\r\n",
        "import argparse\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--n_estimators\", type=int)\r\n",
        "parser.add_argument(\"--min_samples_leaf\", type=int)\r\n",
        "parser.add_argument(\"--datafolder\", type=str)\r\n",
        "\r\n",
        "args, unknown = parser.parse_known_args()\r\n",
        "\r\n",
        "ne = args.n_estimators\r\n",
        "msl = args.min_samples_leaf\r\n",
        "\r\n",
        "print(ne, msl)\r\n",
        "\r\n",
        "X = data_prep.iloc[:, 0:-1]\r\n",
        "\r\n",
        "y = data_prep.iloc[:, -1]\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1234)\r\n",
        "\r\n",
        "# Baseline Random forest based Model\r\n",
        "rfc = RandomForestClassifier(n_estimators=ne, min_samples_leaf=msl)\r\n",
        "rfcg = rfc.fit(X_train, y_train) # fit on training data\r\n",
        "Y_predict = rfcg.predict(X_test)\r\n",
        "\r\n",
        "# Get the probability score - Scored Probabilities\r\n",
        "Y_prob = rfcg.predict_proba(X_test)[:, 1]\r\n",
        "\r\n",
        "# Get Confusion matrix and the accuracy/score - Evaluate\r\n",
        "\r\n",
        "cm    = confusion_matrix(y_test, Y_predict)\r\n",
        "accuracy = accuracy_score(y_test, Y_predict)\r\n",
        "\r\n",
        "# Create the confusion matrix dictionary\r\n",
        "cm_dict = {\"schema_type\": \"confusion_matrix\",\r\n",
        "           \"schema_version\": \"v1\",\r\n",
        "           \"data\": {\"class_labels\": [\"N\", \"Y\"],\r\n",
        "                    \"matrix\": cm.tolist()}\r\n",
        "           }\r\n",
        "\r\n",
        "run.log(\"TotalObservations\", len(dataPrep))\r\n",
        "run.log_confusion_matrix(\"ConfusionMatrix\", cm_dict)\r\n",
        "run.log(\"Accuracy\", accuracy)\r\n",
        "\r\n",
        "# # Save the model in the run outputs\r\n",
        "# os.makedirs('outputs', exist_ok=True)\r\n",
        "# joblib.dump(value=rfc, filename='outputs/insurance_model.pkl')\r\n",
        "\r\n",
        "# # Complete the run\r\n",
        "# run.complete()\r\n",
        "\r\n",
        "# Save the trained model in the outputs folder\r\n",
        "print(\"Saving model...\")\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "model_file = os.path.join('outputs', 'insurance_model.pkl')\r\n",
        "joblib.dump(value=rfc, filename=model_file)\r\n",
        "\r\n",
        "# Register the model\r\n",
        "print('Registering model...')\r\n",
        "Model.register(workspace=run.experiment.workspace,\r\n",
        "               model_path = model_file,\r\n",
        "               model_name = 'diabetes_model',\r\n",
        "               tags={'Training context':'Pipeline'},\r\n",
        "               properties={'Accuracy': np.float(accuracy)})\r\n",
        "\r\n",
        "\r\n",
        "run.complete()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting insurance_pipeline/train_insurance.py\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"saurav-compute-cluster\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679506366913
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/experiment_env.yml\r\n",
        "name: experiment_env\r\n",
        "dependencies:\r\n",
        "- python=3.8\r\n",
        "- scikit-learn\r\n",
        "- ipykernel\r\n",
        "- matplotlib\r\n",
        "- pandas\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults\r\n",
        "  - pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting insurance_pipeline/experiment_env.yml\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "\r\n",
        "# Create a Python environment for the experiment (from a .yml file)\r\n",
        "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\r\n",
        "\r\n",
        "# Register the environment \r\n",
        "experiment_env.register(workspace=ws)\r\n",
        "registered_env = Environment.get(ws, 'experiment_env')\r\n",
        "\r\n",
        "# Create a new runconfig object for the pipeline\r\n",
        "pipeline_run_config = RunConfiguration()\r\n",
        "\r\n",
        "# Use the compute you created above. \r\n",
        "pipeline_run_config.target = pipeline_cluster\r\n",
        "\r\n",
        "# Assign the environment to the run configuration\r\n",
        "pipeline_run_config.environment = registered_env\r\n",
        "\r\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679506384211
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "diabetes_ds = ws.datasets.get(\"insurance dataset\")\r\n",
        "\r\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\r\n",
        "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\r\n",
        "\r\n",
        "# Step 1, Run the data prep script\r\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"prep_insurance.py\",\r\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\r\n",
        "                                             '--prepped-data', prepped_data],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "# Step 2, run the training script\r\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"train_insurance.py\",\r\n",
        "                                arguments = ['--training-data', prepped_data.as_input()],\r\n",
        "                                compute_target = pipeline_cluster,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline steps defined\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679506517228
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Construct the pipeline\r\n",
        "pipeline_steps = [prep_step, train_step]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "# Create an experiment and run the pipeline\r\n",
        "experiment = Experiment(workspace=ws, name = 'saurav-insurance-pipeline')\r\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\r\n",
        "print(\"Pipeline submitted for execution.\")\r\n",
        "RunDetails(pipeline_run).show()\r\n",
        "pipeline_run.wait_for_completion(show_output=True)\r\n",
        "     "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pipeline is built.\nCreated step Prepare Data [9a5816dd][eebeb9bf-8a77-42c6-ac1f-605f574a0f8f], (This step will run and generate new outputs)\nCreated step Train and Register Model [c978cd95][ee975cc2-3164-4089-a8c4-b31874ea0da8], (This step will run and generate new outputs)\nSubmitted PipelineRun 8015f779-539b-49d5-9e4d-9661d7cc8cdf\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/8015f779-539b-49d5-9e4d-9661d7cc8cdf?wsid=/subscriptions/7c248226-48dc-4d36-baa0-0f0883669328/resourcegroups/saurv_01/workspaces/saurav_aml&tid=0563aea9-b886-4b62-9457-a85924a13bd1\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "260307d3e35f400b9c778280a7d05d06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/8015f779-539b-49d5-9e4d-9661d7cc8cdf?wsid=/subscriptions/7c248226-48dc-4d36-baa0-0f0883669328/resourcegroups/saurv_01/workspaces/saurav_aml&tid=0563aea9-b886-4b62-9457-a85924a13bd1\", \"run_id\": \"8015f779-539b-49d5-9e4d-9661d7cc8cdf\", \"run_properties\": {\"run_id\": \"8015f779-539b-49d5-9e4d-9661d7cc8cdf\", \"created_utc\": \"2023-03-22T17:43:01.221961Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\", \"azureml.pipelines.stages\": \"{\\\"Initialization\\\":null,\\\"Execution\\\":{\\\"StartTime\\\":\\\"2023-03-22T17:43:02.1995207+00:00\\\",\\\"EndTime\\\":\\\"2023-03-22T17:44:02.413109+00:00\\\",\\\"Status\\\":\\\"Failed\\\"}}\"}, \"tags\": {}, \"end_time_utc\": \"2023-03-22T17:44:02.575835Z\", \"status\": \"Failed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.8015f779-539b-49d5-9e4d-9661d7cc8cdf/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=08nDb2QXZl2RmXRzJygzyRAMBRIMchEt0Bnoomb4%2FJE%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A23Z&se=2023-03-23T01%3A43%3A23Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.8015f779-539b-49d5-9e4d-9661d7cc8cdf/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=AJe3%2FPF8lvkErcAw%2BQ6Gufo6ScIhiHYpBN6K13QP3Gg%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A23Z&se=2023-03-23T01%3A43%3A23Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.8015f779-539b-49d5-9e4d-9661d7cc8cdf/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=zCEzSCVL3MuT2VIXQo7pmTPDuBngmYvP2iIPs7DypWI%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A23Z&se=2023-03-23T01%3A43%3A23Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:01:01\", \"run_number\": \"1679506981\", \"run_queued_details\": {\"status\": \"Failed\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"fdd667c7-b56d-40c1-9d27-d3dfc55dee9f\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2023-03-22T17:43:10.182514Z\", \"created_time\": \"2023-03-22T17:43:03.194707Z\", \"end_time\": \"2023-03-22T17:43:37.468365Z\", \"duration\": \"0:00:34\", \"run_number\": 1679506983, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-03-22T17:43:03.194707Z\", \"is_reused\": \"\"}, {\"run_id\": \"71f772af-994a-4b70-9a86-383be8072e77\", \"name\": \"Train and Register Model\", \"status\": \"Failed\", \"start_time\": \"2023-03-22T17:43:43.372766Z\", \"created_time\": \"2023-03-22T17:43:39.157933Z\", \"end_time\": \"2023-03-22T17:44:00.871126Z\", \"duration\": \"0:00:21\", \"run_number\": 1679507019, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-03-22T17:43:39.157933Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2023-03-22 17:43:02Z] Submitting 1 runs, first five are: 9a5816dd:fdd667c7-b56d-40c1-9d27-d3dfc55dee9f\\n[2023-03-22 17:43:38Z] Completing processing run id fdd667c7-b56d-40c1-9d27-d3dfc55dee9f.\\n[2023-03-22 17:43:38Z] Submitting 1 runs, first five are: c978cd95:71f772af-994a-4b70-9a86-383be8072e77\\n[2023-03-22 17:44:02Z] Execution of experiment failed, update experiment status and cancel running nodes.\\n\\nError occurred: Pipeline has failed child jobs. For more details and logs, please go to the job detail page and check the child jobs.\\n\", \"graph\": {\"datasource_nodes\": {\"5c904463\": {\"node_id\": \"5c904463\", \"name\": \"insurance dataset\"}}, \"module_nodes\": {\"9a5816dd\": {\"node_id\": \"9a5816dd\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"fdd667c7-b56d-40c1-9d27-d3dfc55dee9f\"}, \"c978cd95\": {\"node_id\": \"c978cd95\", \"name\": \"Train and Register Model\", \"status\": \"Failed\", \"_is_reused\": false, \"run_id\": \"71f772af-994a-4b70-9a86-383be8072e77\"}}, \"edges\": [{\"source_node_id\": \"5c904463\", \"source_node_name\": \"insurance dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"9a5816dd\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"9a5816dd\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_05113398\", \"dst_node_id\": \"c978cd95\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"fdd667c7-b56d-40c1-9d27-d3dfc55dee9f\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2023-03-22T17:43:10.182514Z\", \"created_time\": \"2023-03-22T17:43:03.194707Z\", \"end_time\": \"2023-03-22T17:43:37.468365Z\", \"duration\": \"0:00:34\", \"run_number\": 1679506983, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-03-22T17:43:03.194707Z\", \"is_reused\": \"\"}, {\"run_id\": \"71f772af-994a-4b70-9a86-383be8072e77\", \"name\": \"Train and Register Model\", \"status\": \"Failed\", \"start_time\": \"2023-03-22T17:43:43.372766Z\", \"created_time\": \"2023-03-22T17:43:39.157933Z\", \"end_time\": \"2023-03-22T17:44:00.871126Z\", \"duration\": \"0:00:21\", \"run_number\": 1679507019, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2023-03-22T17:43:39.157933Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.49.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: 8015f779-539b-49d5-9e4d-9661d7cc8cdf\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/8015f779-539b-49d5-9e4d-9661d7cc8cdf?wsid=/subscriptions/7c248226-48dc-4d36-baa0-0f0883669328/resourcegroups/saurv_01/workspaces/saurav_aml&tid=0563aea9-b886-4b62-9457-a85924a13bd1\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: fdd667c7-b56d-40c1-9d27-d3dfc55dee9f\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/fdd667c7-b56d-40c1-9d27-d3dfc55dee9f?wsid=/subscriptions/7c248226-48dc-4d36-baa0-0f0883669328/resourcegroups/saurv_01/workspaces/saurav_aml&tid=0563aea9-b886-4b62-9457-a85924a13bd1\nStepRun( Prepare Data ) Status: Queued\nStepRun( Prepare Data ) Status: Running\n\nStepRun(Prepare Data) Execution Summary\n========================================\nStepRun( Prepare Data ) Status: Finished\n{'runId': 'fdd667c7-b56d-40c1-9d27-d3dfc55dee9f', 'target': 'saurav-compute-cluster', 'status': 'Completed', 'startTimeUtc': '2023-03-22T17:43:10.182514Z', 'endTimeUtc': '2023-03-22T17:43:37.468365Z', 'services': {}, 'properties': {'ContentSnapshotId': '7610b4f1-465e-4585-a15b-350d06f86f85', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'eebeb9bf-8a77-42c6-ac1f-605f574a0f8f', 'azureml.moduleName': 'Prepare Data', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '9a5816dd', 'azureml.pipelinerunid': '8015f779-539b-49d5-9e4d-9661d7cc8cdf', 'azureml.pipeline': '8015f779-539b-49d5-9e4d-9661d7cc8cdf', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '6da6cf53-ab30-4464-b645-a8b03cd8d2a3'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': 'd2e9eb73-1f2d-47a4-bc66-b3eb1dc38cc7'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n  \"source\": [\n    \"('workspaceblobstore', 'dataset/fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/prepped_data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"d2e9eb73-1f2d-47a4-bc66-b3eb1dc38cc7\",\n    \"name\": null,\n    \"version\": null,\n    \"workspace\": \"Workspace.create(name='saurav_aml', subscription_id='7c248226-48dc-4d36-baa0-0f0883669328', resource_group='saurv_01')\"\n  }\n}}], 'runDefinition': {'script': 'prep_insurance.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'saurav-compute-cluster', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '6da6cf53-ab30-4464-b645-a8b03cd8d2a3', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '8015f779-539b-49d5-9e4d-9661d7cc8cdf', 'azureml.pipelineRun.moduleNodeId': '9a5816dd', 'azureml.pipelineRun.outputPortName': 'prepped_data'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '3', 'assetId': 'azureml://locations/eastus2/workspaces/9db2ef5f-31fb-4ace-8eb7-d0b7bd78bc35/environments/experiment_env/versions/3', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'experiment_env', 'dependencies': ['python=3.8', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20230120.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=HLNPRsYbpIpv4Z5B%2FeEOEfYe30dP1k%2FWwPl6jUA%2Bl48%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A32Z&se=2023-03-23T01%3A43%3A32Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=UcnVUhL2bnR%2B0OtauQhbLSN3oDT6shvZ6pOXSIrUqYs%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A32Z&se=2023-03-23T01%3A43%3A32Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2023-03-22-17': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/logs/azureml/dataprep/0/rslex.log.2023-03-22-17?sv=2019-07-07&sr=b&sig=KHCF5zS%2FjVBHYLNwW%2BVyWSnxXseYd37MwnpAnTggAyo%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A32Z&se=2023-03-23T01%3A43%3A32Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=xkiQ%2Buxg%2Bt%2FmV5sEUHFz%2FFEFpvYJ6nblBmzteEmGWj0%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A32Z&se=2023-03-23T01%3A43%3A32Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=%2BziYxDR7uaXlUM3uoR7iOozNO69nqBaHvEB6qXv7cjU%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A32Z&se=2023-03-23T01%3A43%3A32Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=3Fpjdj6Ar4yBKacY4Cc19tLMBRowIusyrfGcPR%2FU%2FoU%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A32Z&se=2023-03-23T01%3A43%3A32Z&sp=r', 'user_logs/std_log.txt': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=CnXtQRjQ8p89VkLJw0nQfGlGIgkSUI9oE9xisr3O9cw%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=yvkwPgIXj0W5RjPFFgXhbdPpeSHtW7yjWD3ShHG33jU%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r', 'system_logs/data_capability/data-capability.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=Wp2hLBV1OeqgfnliG2Crd8tPTibRwtOcls8WIUFQAxw%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r', 'system_logs/data_capability/rslex.log.2023-03-22-17': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/system_logs/data_capability/rslex.log.2023-03-22-17?sv=2019-07-07&sr=b&sig=%2BsH7PhhUqAGqz06hKnEH4VCDlRz%2Bb0CXe%2FM7e%2FtLLlU%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=NDvx4J%2BC6ZspBp8%2Bz6661Q1K6fbCTEYuBqhjOLrlNJw%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=PQ8V0jGoaPaNxcA48z88eTgDORk1IKHmJf5Py8LEq4c%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=fSAjTOVGvssvg9vcT649F3QNInjDgvF26D8Ea78ZCSY%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=lxld2pvuAUt684SdJ3a7jRss4RRMJ1SOPizDtQu23Sc%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://sauravaml7390822349.blob.core.windows.net/azureml/ExperimentRun/dcid.fdd667c7-b56d-40c1-9d27-d3dfc55dee9f/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=L09%2F7v%2FaLLWPr02Dj1JLzCMnGPmOT7D%2F2AKyBEukAvY%3D&skoid=d4a5ccdf-0157-4f3b-b8b0-16434308cc74&sktid=0563aea9-b886-4b62-9457-a85924a13bd1&skt=2023-03-22T17%3A16%3A30Z&ske=2023-03-24T01%3A26%3A30Z&sks=b&skv=2019-07-07&st=2023-03-22T17%3A33%3A39Z&se=2023-03-23T01%3A43%3A39Z&sp=r'}, 'submittedBy': 'saurav kumar'}\n\n\n\n\nStepRunId: 71f772af-994a-4b70-9a86-383be8072e77\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/71f772af-994a-4b70-9a86-383be8072e77?wsid=/subscriptions/7c248226-48dc-4d36-baa0-0f0883669328/resourcegroups/saurv_01/workspaces/saurav_aml&tid=0563aea9-b886-4b62-9457-a85924a13bd1\nStepRun( Train and Register Model ) Status: NotStarted\n\nStepRun(Train and Register Model) Execution Summary\n====================================================\nStepRun( Train and Register Model ) Status: Failed\n\nWarnings:\nAzureMLCompute job failed.\nExecutionFailed: [REDACTED]\n\texit_codes: 1\n\tAppinsights Reachable: Some(true)\nExecution failed. User process '/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\n  File \"train_insuranc\n"
        },
        {
          "output_type": "error",
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"train_insurance.py\\\", line 17, in <module>\\n    from sklearn.tree import RandomForestClassifier\\nImportError: cannot import name 'RandomForestClassifier' from 'sklearn.tree' (/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages/sklearn/tree/__init__.py)\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"train_insurance.py\\\\\\\", line 17, in <module>\\\\n    from sklearn.tree import RandomForestClassifier\\\\nImportError: cannot import name 'RandomForestClassifier' from 'sklearn.tree' (/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages/sklearn/tree/__init__.py)\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline submitted for execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m RunDetails(pipeline_run)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mpipeline_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:295\u001b[0m, in \u001b[0;36mPipelineRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[43mstep_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# If there are package conflicts in the user's environment, the run rehydration\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# will not work and we will receive a Run object instead of StepRun.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Run.wait_for_completion() does not have a parameter timeout_seconds, which\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# will generate a TypeError here.  As a workaround, call the method without\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# this parameter.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step_run, StepRun):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:738\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    743\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    744\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:831\u001b[0m, in \u001b[0;36mStepRun._stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m raise_on_error:\n\u001b[0;32m--> 831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_details)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Execution failed. User process '/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\n  File \\\"train_insurance.py\\\", line 17, in <module>\\n    from sklearn.tree import RandomForestClassifier\\nImportError: cannot import name 'RandomForestClassifier' from 'sklearn.tree' (/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages/sklearn/tree/__init__.py)\\n\\n\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\",\n    \"componentName\": \"CommonRuntime\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Execution failed. User process '/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/bin/python' exited with status code 1. Please check log file 'user_logs/std_log.txt' for error details. Error: Traceback (most recent call last):\\\\n  File \\\\\\\"train_insurance.py\\\\\\\", line 17, in <module>\\\\n    from sklearn.tree import RandomForestClassifier\\\\nImportError: cannot import name 'RandomForestClassifier' from 'sklearn.tree' (/azureml-envs/azureml_f102ca25577426a3b1fe82a38ab699fe/lib/python3.8/site-packages/sklearn/tree/__init__.py)\\\\n\\\\n\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\",\\n    \\\"componentName\\\": \\\"CommonRuntime\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1679507575666
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}